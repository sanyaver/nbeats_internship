{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from time import time\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import mse_loss, l1_loss, binary_cross_entropy, cross_entropy\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NBeatsNet(nn.Module):\n",
    "    SEASONALITY_BLOCK = 'seasonality'\n",
    "    TREND_BLOCK = 'trend'\n",
    "    GENERIC_BLOCK = 'generic'\n",
    "\n",
    "    def __init__(self,\n",
    "                 device=torch.device('cpu'),\n",
    "                 stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
    "                 nb_blocks_per_stack=3,\n",
    "                 forecast_length=5,\n",
    "                 backcast_length=10,\n",
    "                 thetas_dim=(4, 8),\n",
    "                 share_weights_in_stack=False,\n",
    "                 hidden_layer_units=256,\n",
    "                 nb_harmonics=None):\n",
    "        super(NBeatsNet, self).__init__()\n",
    "        self.forecast_length = forecast_length\n",
    "        self.backcast_length = backcast_length\n",
    "        self.hidden_layer_units = hidden_layer_units\n",
    "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
    "        self.share_weights_in_stack = share_weights_in_stack\n",
    "        self.nb_harmonics = nb_harmonics\n",
    "        self.stack_types = stack_types\n",
    "        self.stacks = []\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.parameters = []\n",
    "        self.device = device\n",
    "        print('| N-Beats')\n",
    "        for stack_id in range(len(self.stack_types)):\n",
    "            self.stacks.append(self.create_stack(stack_id))\n",
    "        self.parameters = nn.ParameterList(self.parameters)\n",
    "        self.to(self.device)\n",
    "        self._loss = None\n",
    "        self._opt = None\n",
    "\n",
    "    def create_stack(self, stack_id):\n",
    "        stack_type = self.stack_types[stack_id]\n",
    "        print(f'| --  Stack {stack_type.title()} (#{stack_id}) (share_weights_in_stack={self.share_weights_in_stack})')\n",
    "        blocks = []\n",
    "        for block_id in range(self.nb_blocks_per_stack):\n",
    "            block_init = NBeatsNet.select_block(stack_type)\n",
    "            if self.share_weights_in_stack and block_id != 0:\n",
    "                block = blocks[-1]  # pick up the last one when we share weights.\n",
    "            else:\n",
    "                block = block_init(self.hidden_layer_units, self.thetas_dim[stack_id],\n",
    "                                   self.device, self.backcast_length, self.forecast_length, self.nb_harmonics)\n",
    "                self.parameters.extend(block.parameters())\n",
    "            print(f'     | -- {block}')\n",
    "            blocks.append(block)\n",
    "        return blocks\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        torch.save(self, filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(f, map_location=None, pickle_module=pickle, **pickle_load_args):\n",
    "        return torch.load(f, map_location, pickle_module, **pickle_load_args)\n",
    "\n",
    "    @staticmethod\n",
    "    def select_block(block_type):\n",
    "        if block_type == NBeatsNet.SEASONALITY_BLOCK:\n",
    "            return SeasonalityBlock\n",
    "        elif block_type == NBeatsNet.TREND_BLOCK:\n",
    "            return TrendBlock\n",
    "        else:\n",
    "            return GenericBlock\n",
    "\n",
    "    def compile(self, loss: str, optimizer: Union[str, Optimizer]):\n",
    "        if loss == 'mae':\n",
    "            loss_ = l1_loss\n",
    "        elif loss == 'mse':\n",
    "            loss_ = mse_loss\n",
    "        elif loss == 'cross_entropy':\n",
    "            loss_ = cross_entropy\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            loss_ = binary_cross_entropy\n",
    "        else:\n",
    "            raise ValueError(f'Unknown loss name: {loss}.')\n",
    "        # noinspection PyArgumentList\n",
    "        if isinstance(optimizer, str):\n",
    "            if optimizer == 'adam':\n",
    "                opt_ = optim.Adam\n",
    "            elif optimizer == 'sgd':\n",
    "                opt_ = optim.SGD\n",
    "            elif optimizer == 'rmsprop':\n",
    "                opt_ = optim.RMSprop\n",
    "            else:\n",
    "                raise ValueError(f'Unknown opt name: {optimizer}.')\n",
    "            opt_ = opt_(lr=1e-4, params=self.parameters())\n",
    "        else:\n",
    "            opt_ = optimizer\n",
    "        self._opt = opt_\n",
    "        self._loss = loss_\n",
    "\n",
    "    def fit(self, x_train, y_train, validation_data=None, epochs=10, batch_size=32):\n",
    "\n",
    "        def split(arr, size):\n",
    "            arrays = []\n",
    "            while len(arr) > size:\n",
    "                slice_ = arr[:size]\n",
    "                arrays.append(slice_)\n",
    "                arr = arr[size:]\n",
    "            arrays.append(arr)\n",
    "            return arrays\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            x_train_list = split(x_train, batch_size)\n",
    "            y_train_list = split(y_train, batch_size)\n",
    "            assert len(x_train_list) == len(y_train_list)\n",
    "            shuffled_indices = list(range(len(x_train_list)))\n",
    "            random.shuffle(shuffled_indices)\n",
    "            self.train()\n",
    "            train_loss = []\n",
    "            timer = time()\n",
    "            for batch_id in shuffled_indices:\n",
    "                batch_x, batch_y = x_train_list[batch_id], y_train_list[batch_id]\n",
    "                self._opt.zero_grad()\n",
    "                _, forecast = self(torch.tensor(batch_x, dtype=torch.float).to(self.device))\n",
    "                loss = self._loss(forecast, squeeze_last_dim(torch.tensor(batch_y, dtype=torch.float).to(self.device)))\n",
    "                train_loss.append(loss.item())\n",
    "                loss.backward()\n",
    "                self._opt.step()\n",
    "            elapsed_time = time() - timer\n",
    "            train_loss = np.mean(train_loss)\n",
    "\n",
    "            test_loss = '[undefined]'\n",
    "            if validation_data is not None:\n",
    "                x_test, y_test = validation_data\n",
    "                self.eval()\n",
    "                _, forecast = self(torch.tensor(x_test, dtype=torch.float).to(self.device))\n",
    "                test_loss = self._loss(forecast, squeeze_last_dim(torch.tensor(y_test, dtype=torch.float))).item()\n",
    "\n",
    "            num_samples = len(x_train_list)\n",
    "            time_per_step = int(elapsed_time / num_samples * 1000)\n",
    "            print(f'Epoch {str(epoch + 1).zfill(len(str(epochs)))}/{epochs}')\n",
    "            print(f'{num_samples}/{num_samples} [==============================] - '\n",
    "                  f'{int(elapsed_time)}s {time_per_step}ms/step - '\n",
    "                  f'loss: {train_loss:.4f} - val_loss: {test_loss:.4f}')\n",
    "\n",
    "    def predict(self, x, return_backcast=False):\n",
    "        self.eval()\n",
    "        b, f = self(torch.tensor(x, dtype=torch.float).to(self.device))\n",
    "        b, f = b.detach().numpy(), f.detach().numpy()\n",
    "        if len(x.shape) == 3:\n",
    "            b = np.expand_dims(b, axis=-1)\n",
    "            f = np.expand_dims(f, axis=-1)\n",
    "        if return_backcast:\n",
    "            return b\n",
    "        return f\n",
    "\n",
    "    def forward(self, backcast):\n",
    "        backcast = squeeze_last_dim(backcast)\n",
    "        forecast = torch.zeros(size=(backcast.size()[0], self.forecast_length,))  # maybe batch size here.\n",
    "        for stack_id in range(len(self.stacks)):\n",
    "            for block_id in range(len(self.stacks[stack_id])):\n",
    "                b, f = self.stacks[stack_id][block_id](backcast)\n",
    "                backcast = backcast.to(self.device) - b\n",
    "                forecast = forecast.to(self.device) + f\n",
    "        return backcast, forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def squeeze_last_dim(tensor):\n",
    "    if len(tensor.shape) == 3 and tensor.shape[-1] == 1:  # (128, 10, 1) => (128, 10).\n",
    "        return tensor[..., 0]\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def seasonality_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    assert p <= thetas.shape[1], 'thetas_dim is too big.'\n",
    "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
    "    s1 = torch.tensor([np.cos(2 * np.pi * i * t) for i in range(p1)]).float()  # H/2-1\n",
    "    s2 = torch.tensor([np.sin(2 * np.pi * i * t) for i in range(p2)]).float()\n",
    "    S = torch.cat([s1, s2])\n",
    "    return thetas.mm(S.to(device))\n",
    "\n",
    "\n",
    "def trend_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    assert p <= 4, 'thetas_dim is too big.'\n",
    "    T = torch.tensor([t ** i for i in range(p)]).float()\n",
    "    return thetas.mm(T.to(device))\n",
    "\n",
    "\n",
    "def linear_space(backcast_length, forecast_length, is_forecast=True):\n",
    "    horizon = forecast_length if is_forecast else backcast_length\n",
    "    return np.arange(0, horizon) / horizon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, share_thetas=False,\n",
    "                 nb_harmonics=None):\n",
    "        super(Block, self).__init__()\n",
    "        self.units = units\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.backcast_length = backcast_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.share_thetas = share_thetas\n",
    "        self.fc1 = nn.Linear(backcast_length, units)\n",
    "        self.fc2 = nn.Linear(units, units)\n",
    "        self.fc3 = nn.Linear(units, units)\n",
    "        self.fc4 = nn.Linear(units, units)\n",
    "        self.device = device\n",
    "        self.backcast_linspace = linear_space(backcast_length, forecast_length, is_forecast=False)\n",
    "        self.forecast_linspace = linear_space(backcast_length, forecast_length, is_forecast=True)\n",
    "        if share_thetas:\n",
    "            self.theta_f_fc = self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "        else:\n",
    "            self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "            self.theta_f_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = squeeze_last_dim(x)\n",
    "        x = F.relu(self.fc1(x.to(self.device)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        block_type = type(self).__name__\n",
    "        return f'{block_type}(units={self.units}, thetas_dim={self.thetas_dim}, ' \\\n",
    "               f'backcast_length={self.backcast_length}, forecast_length={self.forecast_length}, ' \\\n",
    "               f'share_thetas={self.share_thetas}) at @{id(self)}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeasonalityBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        if nb_harmonics:\n",
    "            super(SeasonalityBlock, self).__init__(units, nb_harmonics, device, backcast_length,\n",
    "                                                   forecast_length, share_thetas=True)\n",
    "        else:\n",
    "            super(SeasonalityBlock, self).__init__(units, forecast_length, device, backcast_length,\n",
    "                                                   forecast_length, share_thetas=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(SeasonalityBlock, self).forward(x)\n",
    "        backcast = seasonality_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
    "        forecast = seasonality_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
    "        return backcast, forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrendBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        super(TrendBlock, self).__init__(units, thetas_dim, device, backcast_length,\n",
    "                                         forecast_length, share_thetas=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(TrendBlock, self).forward(x)\n",
    "        backcast = trend_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
    "        forecast = trend_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
    "        return backcast, forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GenericBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        super(GenericBlock, self).__init__(units, thetas_dim, device, backcast_length, forecast_length)\n",
    "\n",
    "        self.backcast_fc = nn.Linear(thetas_dim, backcast_length)\n",
    "        self.forecast_fc = nn.Linear(thetas_dim, forecast_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # no constraint for generic arch.\n",
    "        x = super(GenericBlock, self).forward(x)\n",
    "\n",
    "        theta_b = self.theta_b_fc(x)\n",
    "        theta_f = self.theta_f_fc(x)\n",
    "\n",
    "        backcast = self.backcast_fc(theta_b)  # generic. 3.3.\n",
    "        forecast = self.forecast_fc(theta_f)  # generic. 3.3.\n",
    "\n",
    "        return backcast, forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "186eabbcebe7909033e56b56026d7f17efc88f9d69279fedcd7468a23daf4403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
